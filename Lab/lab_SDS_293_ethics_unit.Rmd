---
title: "Lab# - Fairness"
author: "SDS 293: Modeling for Machine Learning"
date: "Fall 2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(eval = FALSE)

```

```{r libraries}
library(reticulate) # provides a comprehensive set of tools for interoperability between Python and R.
```

```{r set up the python environment}

# configure python
reticulate::py_config() # Double check that reticulate is actually using your new conda env.

# install the Python libraries if you don't already have them installed on your computer.
reticulate::py_install("sklearn", pip = TRUE) # force install with pip. sklearn wasn't coming up via anaconda.
reticulate::py_install("matplotlib")
reticulate::py_install("keras")
reticulate::py_install("tensorflow")

# It will probably take a little while so be patient and try to avoid accidentally running
# this chunk of code.

# common trouble shooting:
# step 1: if you're missing a package then try adding its name in an additional 
# line of py_install with that package.
# step 2: if py_install isn't working then try adding the pip = TRUE argument to 
# try installing the library through pip rather than anaconda
```

# Goals for this lab
Compute trust scores for the model's predictions of wine types and handwritten numbers.
Practice working with Python in an R environment.

# Note:
The content of this lab is overwhelmingly from Google's Trust Scores paper and 
published code, just converted to work in R. The paper, code, and other resources are cited below.
This includes needing to have the trustscore.py and trustscore_evaluation.py files
in the same folder as this lab becuase the Python functions are sourced
directly from those files created by the paper's authors.

```{python}
import numpy as np
import trustscore # you need to have trustscore.py in the same folder as this .Rmd file to import it
import trustscore_evaluation  # you need to have trustscore_evaluation.py in the same folder as this .Rmd file to import it
import numpy as np
import matplotlib.pyplot as plt
import keras

# heads up! there might be some scary errors about "dlerror: cudart64_110.dll not found". It's a warning and you can ignore it safely.

```

```{python}
# Import the default data sets from SK learn: the wine dataset and the classifying
# United States Post Office digits / handwriting.
from sklearn import datasets
wine = datasets.load_wine()
X_wine = wine.data
y_wine = wine.target
digits = datasets.load_digits()
X_digits = digits.data
y_digits = digits.target

datasets = [(X_wine, y_wine), (X_digits, y_digits)]
dataset_names = ["Wine", "Digits"]

```

```{python}
# trust scores for linear regression

from sklearn.linear_model import LogisticRegression

# Train logistic regression on digits.
model = LogisticRegression()
model.fit(X_digits[:1300], y_digits[:1300])

# Get outputs on testing set.
y_pred = model.predict(X_digits[1300:])

# Initialize trust score.
trust_model = trustscore.TrustScore()
trust_model.fit(X_digits[:1300], y_digits[:1300])

# Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.
trust_score = trust_model.get_score(X_digits[1300:], y_pred)

print(trust_score) # prints the trust scores for each point in the inputted dataset

# type(trust_score) # this trust_score dataframe has a class of <class 'numpy.ndarray'>

```

# Check for understanding:
Why are the trust scores generally between 0 and 2?'


Are there any negative trust scores? Why do you think that is?
(Hint: think about the independent functions that create each trust score's numeric value)


Do a quick skim and find a trust score that is an outliar compared to the other numbers. Describe that trust score's numeric value through its context in the model as a whole.



```{r accessing Python objects in R}
# Detour --- extra coding skills (optional)

# You can access variables created in the Python environment in the R studio Python 
# environment but not the R environment, unless you define the objects within an
# R chunk.
# we can access to objects created within Python chunks from R using the py object (e.g. py$x would access an x variable created within Python from R).

class(py$trust_score) # should be an array 

# create an object in R by creating an R variable in an R code chunk
trust_score_as_an_R_data_structure <- py$trust_score

```

```{python}
# Creates graphs about how correct the preduction is for the wine dataset via logistic regression

# this will produce matplotlib graphs below the code chunk, like how ggplot does.
# it will also produce some scary looking but generally ignoreable text about
# reaching the total number of iterations.
# According to Stack Overflow, this means
# "On the other hand, if the error is varying noticeably (even if the error is 
# relatively small [like in your case the score was good], but rather the differences 
# between the errors per iteration is greater than some tolerance) then we say the 
# algorithm did not converge." - https://stackoverflow.com/a/62659927

for dataset_idx,  dataset_name in enumerate(dataset_names):
  extra_plot_title = dataset_name + " | Logistic Regression | Predict Correct"
  percentile_levels = [0 + 0.5 * i for i in range(200)]
  signal_names = ["Trust Score"]
  signals = [trustscore.TrustScore()]
  trainer = trustscore_evaluation.run_logistic
  X, y = datasets[dataset_idx]
  trustscore_evaluation.run_precision_recall_experiment_general(X,
                                                                y,
                                                                n_repeats=10,
                                                                percentile_levels=percentile_levels,
                                                                trainer=trainer,
                                                                signal_names=signal_names,
                                                                signals=signals,
                                                                extra_plot_title=extra_plot_title,
                                                                skip_print=True,
                                                                predict_when_correct=True)

```


```{python}
# Create a graph about the points in the Wine dataset that were classified incorrectly, broken down by the model confidence and the trust score

for dataset_idx,  dataset_name in enumerate(dataset_names):
  extra_plot_title = dataset_name + " | Logistic Regression | Predict Incorrect"
  percentile_levels = [70 + 0.5 * i for i in range(60)]
  signal_names = ["Trust Score"]
  signals = [trustscore.TrustScore()]
  trainer = trustscore_evaluation.run_logistic
  X, y = datasets[dataset_idx]
  trustscore_evaluation.run_precision_recall_experiment_general(X,
                                                                y,
                                                                n_repeats=10,
                                                                percentile_levels=percentile_levels,
                                                                trainer=trainer,
                                                                signal_names=signal_names,
                                                                signals=signals,
                                                                extra_plot_title=extra_plot_title,
                                                                skip_print=True)


```
# Check for understanding:
Explain what the x-axis and y-axis of this graph means, in one to two sentences.

# Going a step further
Try another model from the trustscore_evaluation.py file, like run_random_forest() or run_simple_NN().


# Submitting this lab

Write about a situation in a past lab or real-life where you wish you could have used trust scores or a similar metric to check your model's predictions. If you cannot think of a situation, then detail why you don't think trust scores were necessary for that model.


# References:
Jiang, H., & Hembise, C. (n.d.). *Google/TrustScore: To trust or not to trust a classifier. A measure of uncertainty for any trained (possibly Black-box) classifier which is more effective than the classifier's own implied confidence (e.g. softmax probability for a neural network)*. GitHub. Retrieved December 22, 2021, from https://github.com/google/TrustScore

Jiang, H., Kim, B., Guan, M. Y., & Gupta, M. (2018, October 26). *To trust or not to trust a classifier*. arXiv.org. Retrieved December 22, 2021, from https://arxiv.org/abs/1805.11783 

Gajane, P., & Pechenizkiy, M. (2018, May 28). *On formalizing fairness in prediction with machine learning*. arXiv.org. Retrieved December 22, 2021, from https://arxiv.org/abs/1710.03184 

Papernot, N., & McDaniel, P. (2018, March 13). *Deep K-nearest neighbors: Towards confident, interpretable and robust deep learning*. arXiv.org. Retrieved December 22, 2021, from https://arxiv.org/abs/1803.04765v1

Interface to python. Interface to Python â€¢ reticulate. (n.d.). Retrieved December 22, 2021, from https://rstudio.github.io/reticulate/ 

Yahya, & Mortensen, P. (2021, May 8). *Convergencewarning: Lbfgs failed to converge (status=1): Stop: Total no. of iterations reached limit*. Stack Overflow. Retrieved December 22, 2021, from https://stackoverflow.com/a/62659927


# Licence:
This teachable unit is created from the references listed above, as well as my own work. It is offered under the Apache Licence.

Copyright 2021 Sarah Gillespie

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
